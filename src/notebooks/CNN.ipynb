{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'..')\n",
    "import bitmap\n",
    "import itertools\n",
    "from forward_prediction import forward_model as actual_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGENERATE_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load training data\n",
    "N = 128000\n",
    "\n",
    "if REGENERATE_DATA:\n",
    "    train_data_gen = bitmap.generate_train_set(N, 41, min_delta=1, max_delta=1)\n",
    "    deltas, start_boards, stop_boards = map(np.array, zip(*list(train_data_gen)))\n",
    "    # Save training data\n",
    "    np.save('../../data/training_start_boards', start_boards)\n",
    "    np.save('../../data/training_stop_boards', stop_boards)\n",
    "else:\n",
    "    start_boards = np.load('../../data/training_start_boards.npy')\n",
    "    stop_boards = np.load('../../data/training_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load validation data\n",
    "N_valid = 12800\n",
    "\n",
    "if REGENERATE_DATA:\n",
    "    valid_data_gen = bitmap.generate_train_set(N_valid, 1024, min_delta=1, max_delta=1)\n",
    "    deltas, valid_start_boards, valid_stop_boards = map(np.array, zip(*list(valid_data_gen)))\n",
    "    # Save validation data\n",
    "    np.save('../../data/valid_start_boards', valid_start_boards)\n",
    "    np.save('../../data/valid_stop_boards', valid_stop_boards)\n",
    "else:\n",
    "    valid_start_boards = np.load('../../data/valid_start_boards.npy')\n",
    "    valid_stop_boards = np.load('../../data/valid_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = Variable(torch.tensor(valid_start_boards).view(N_valid, 1, 25, 25).float())\n",
    "y_valid = Variable(torch.tensor(valid_stop_boards).view(N_valid, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load test data\n",
    "N_test = 25600\n",
    "\n",
    "if REGENERATE_DATA:\n",
    "    test_data_gen = bitmap.generate_train_set(N_test, 42, min_delta=1, max_delta=1)\n",
    "    deltas, test_start_boards, test_stop_boards = map(np.array, zip(*list(test_data_gen)))\n",
    "    # Save test data\n",
    "    np.save('../../data/test_start_boards', test_start_boards)\n",
    "    np.save('../../data/test_stop_boards', test_stop_boards)\n",
    "else:\n",
    "    test_start_boards = np.load('../../data/test_start_boards.npy')\n",
    "    test_stop_boards = np.load('../../data/test_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, X_valid, y_valid, \n",
    "          optim, criterion, output_path, num_epochs=50, batch_size=128):\n",
    "    # Release CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = optim(model.parameters())\n",
    "    \n",
    "    # Setup Tensorboard (https://pytorch.org/docs/stable/tensorboard.html)\n",
    "    writer = SummaryWriter()\n",
    "    # writer.add_graph(model.cpu(), X)\n",
    "    model.cuda()\n",
    "\n",
    "    # Best validation MAE\n",
    "    best_valid_mae = 1\n",
    "    \n",
    "    # Train\n",
    "    n_iter = 0\n",
    "    for epoch in range(num_epochs): \n",
    "        permutation = torch.randperm(X.size()[0])\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(range(0, X.size()[0], batch_size))\n",
    "        for i in pbar:\n",
    "            n_iter += 1\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch = X[indices].cuda()\n",
    "            target = y[indices].cuda()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate MAE\n",
    "            if hasattr(model, \"reverse_net\"):\n",
    "                pred_start_boards = model.reverse_net(batch)\n",
    "                outputs = actual_forward.forward((pred_start_boards > 0.5).int())\n",
    "            output_boards = (outputs > 0.5).int()\n",
    "            mae = torch.sum(output_boards != target).float() / (batch_size * 25 * 25)\n",
    "            \n",
    "            # Write data to Tensorboard\n",
    "            writer.add_scalar('Loss/train', loss.item(), n_iter)\n",
    "            writer.add_scalar('MAE/train', mae.item(), n_iter)\n",
    "            \n",
    "            pbar.set_description(\"[{:d}, {:5d}] loss: {:.6f} | train MAE {:.6f} | best MAE: {:.6f}\".format(epoch + 1, i + 1, loss.item(), mae, best_valid_mae))\n",
    "            \n",
    "            # Write boards and validation results to Tensorboard every 10 batches\n",
    "            if n_iter % 10 == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    valid_loss = 0\n",
    "                    valid_mae = 0\n",
    "                    m = 0\n",
    "                    for j in range(0, X_valid.size()[0], batch_size):\n",
    "                        m += 1\n",
    "                        valid_batch = X_valid[j:j+batch_size].cuda()\n",
    "                        valid_target = y_valid[j:j+batch_size].cuda()\n",
    "                        valid_outputs = model(valid_batch)\n",
    "                        valid_loss += criterion(valid_outputs, valid_target)\n",
    "                        if hasattr(model, \"reverse_net\"):\n",
    "                            valid_start_boards = model.reverse_net(valid_batch)\n",
    "                            valid_outputs = actual_forward.forward((valid_start_boards > 0.5).int())\n",
    "                        valid_boards = (valid_outputs > 0.5).int()\n",
    "                        valid_mae += torch.sum(valid_boards != valid_target).float()\n",
    "                    valid_loss /= m\n",
    "                    valid_mae /= (X_valid.size()[0] * 25 * 25)\n",
    "                    writer.add_image('predicted stop board', valid_boards[-1], n_iter)\n",
    "                    writer.add_image('actual stop board', y_valid[-1], n_iter)\n",
    "                    if hasattr(model, \"reverse_net\"):\n",
    "                        # pred_start_board = (model.reverse_net(X_valid[-1].view(1, 1, 25, 25).cuda()) > 0.5).int()\n",
    "                        # writer.add_image('predicted start board', pred_start_board[-1], n_iter)\n",
    "                        writer.add_image('predicted start board', (valid_start_boards[-1] > 0.5).int(), n_iter)\n",
    "                    writer.add_scalar('Loss/valid', valid_loss.item(), n_iter)\n",
    "                    writer.add_scalar('MAE/valid', valid_mae.item(), n_iter)\n",
    "                    \n",
    "                if valid_mae < best_valid_mae:\n",
    "                    best_valid_mae = valid_mae\n",
    "                    # Save model if we have the lastest best MAE\n",
    "                    torch.save(model.state_dict(), output_path)\n",
    "    writer.close()\n",
    "    print(\"The best validation MAE: {}\".format(best_valid_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_mae(model, weight_path, input_boards, output_boards, n):\n",
    "    # Release CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "    # Load model\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model.cuda()\n",
    "    # Convert boards to tensor\n",
    "    input_boards_tensor = torch.tensor(input_boards[:n]).view(n, 1, 25, 25).float().cuda()\n",
    "    output_boards_tensor = torch.tensor(output_boards[:n]).view(n, 1, 25, 25)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Make prediction\n",
    "        if hasattr(model, \"reverse_net\"):\n",
    "            predicted_start_board = model.reverse_net(input_boards_tensor)\n",
    "            predicted_output_board = (actual_forward.forward((predicted_start_board > 0.5).int()) > 0.5).int()\n",
    "        else:\n",
    "            predicted_output_board = (model(input_boards_tensor) > 0.5).int()\n",
    "        error = torch.sum(predicted_output_board.cpu() != output_boards_tensor)\n",
    "        # print(predicted_stop_board)\n",
    "        # print(stop_boards_tensor)\n",
    "        return error / (n * 25 * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForwardNet, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_net = ForwardNet()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.tensor(start_boards[:25600]).view(25600, 1, 25, 25).float(), requires_grad=True)\n",
    "y = Variable(torch.tensor(stop_boards[:25600]).view(25600, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_forward_model_path = \"../models/johnson/vanilla_forward.pkl\"\n",
    "forward_net.load_state_dict(torch.load(vanilla_forward_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the forward model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(forward_net, X, y, X_valid, y_valid, optim.Adam, criterion, vanilla_forward_model_path, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data MAE\n",
    "train_mae = get_forward_mae(forward_net, vanilla_forward_model_path, \n",
    "                            start_boards, stop_boards, 25600)\n",
    "print(\"The training data MAE is {:.8f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "test_mae = get_forward_mae(forward_net, vanilla_forward_model_path,\n",
    "                           test_start_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.8f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax starting boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify starting boards \n",
    "def relax_boards(boards):\n",
    "    np.random.seed(41)\n",
    "    return np.abs(np.random.rand(*boards.shape) / 2 - boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_start_boards = relax_boards(start_boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelaxedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelaxedForwardNet, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 8, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_forward_net = RelaxedForwardNet()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_relaxed = Variable(torch.tensor(relaxed_start_boards).view(N, 1, 25, 25).float(), requires_grad=True)\n",
    "y = Variable(torch.tensor(stop_boards).view(N, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_valid_start_boards = relax_boards(valid_start_boards)\n",
    "X_valid_relaxed = Variable(torch.tensor(relaxed_valid_start_boards).view(N_valid, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relaxed_forward_model_path = \"../models/johnson/relaxed_forward.pkl\"\n",
    "# relaxed_forward_model_path = \"../models/best/relaxed_forward.pkl\"\n",
    "relaxed_forward_net.load_state_dict(torch.load(relaxed_forward_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the _relaxed_ forward model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1, 127745] loss: 0.006373 | train MAE 0.001762 | best MAE: 0.002004: 100%|██████████| 500/500 [01:00<00:00,  8.32it/s]\n",
      "[2, 127745] loss: 0.006227 | train MAE 0.002000 | best MAE: 0.001964: 100%|██████████| 500/500 [00:57<00:00,  8.68it/s]\n",
      "[3, 127745] loss: 0.006734 | train MAE 0.002025 | best MAE: 0.001844: 100%|██████████| 500/500 [00:57<00:00,  8.71it/s]\n",
      "[4, 127745] loss: 0.005842 | train MAE 0.002181 | best MAE: 0.001747: 100%|██████████| 500/500 [00:57<00:00,  8.72it/s]\n",
      "[5, 127745] loss: 0.006753 | train MAE 0.002212 | best MAE: 0.001747: 100%|██████████| 500/500 [00:57<00:00,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation MAE: 0.001746749971061945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(relaxed_forward_net, X_relaxed, y, X_valid_relaxed, y_valid, optim.Adam, criterion, relaxed_forward_model_path, batch_size=256, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data MAE is 0.001715.\n",
      "The test data MAE is 0.001719.\n"
     ]
    }
   ],
   "source": [
    "# Training data MAE\n",
    "train_mae = get_forward_mae(relaxed_forward_net, relaxed_forward_model_path, relaxed_start_boards, stop_boards, N // 2)\n",
    "print(\"The training data MAE is {:.6f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "relaxed_test_start_boards = relax_boards(test_start_boards)\n",
    "test_mae = get_forward_mae(relaxed_forward_net, relaxed_forward_model_path, relaxed_test_start_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.6f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New training data just for the reverse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGENERATE_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load training data\n",
    "N_reverse = 51200\n",
    "\n",
    "if REGENERATE_DATA:\n",
    "    train_data_gen = bitmap.generate_train_set(N_reverse, 2, min_delta=1, max_delta=1)\n",
    "    deltas, r_start_boards, r_stop_boards = map(np.array, zip(*list(train_data_gen)))\n",
    "    # Save training data\n",
    "    np.save('../../data/reverse_start_boards', r_start_boards)\n",
    "    np.save('../../data/reverse_stop_boards', r_stop_boards)\n",
    "else:\n",
    "    r_start_boards = np.load('../../data/reverse_start_boards.npy')\n",
    "    r_stop_boards = np.load('../../data/reverse_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetA, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 4, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1_7 = nn.Conv2d(4, 4, (7, 7), padding=(3, 3), padding_mode='circular')\n",
    "        self.conv1_5 = nn.Conv2d(4, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv1_3 = nn.Conv2d(4, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.conv1_1 = nn.Conv2d(4, 4, (1, 1))\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2_5 = nn.Conv2d(16, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv2_3 = nn.Conv2d(16, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(torch.cat((self.conv1_1(x), self.conv1_3(x), \n",
    "                                   self.conv1_5(x), self.conv1_7(x)), 1))\n",
    "        x = self.activ2(torch.cat((self.conv2_3(x), self.conv2_5(x)), 1))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetB, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 4, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1_5 = nn.Conv2d(4, 8, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv1_3 = nn.Conv2d(4, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2_5 = nn.Conv2d(16, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv2_3 = nn.Conv2d(16, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(torch.cat((self.conv1_3(x), self.conv1_5(x)), 1))\n",
    "        x = self.activ2(torch.cat((self.conv2_3(x), self.conv2_5(x)), 1))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetC, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 8, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetD, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 16, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(16, 32, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.bn1 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.bn2 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.bn3 = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ4 = nn.PReLU()\n",
    "        self.conv5 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(self.bn1(self.conv1(x)))\n",
    "        x = self.activ2(self.bn2(self.conv2(x)))\n",
    "        x = self.activ3(self.bn3(self.conv3(x)))\n",
    "        x = self.activ4(self.conv4(x))\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse model version E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetE, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 16, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1_7 = nn.Conv2d(16, 8, (7, 7), padding=(3, 3), padding_mode='circular')\n",
    "        self.conv1_5 = nn.Conv2d(16, 8, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv1_3 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.conv1_1 = nn.Conv2d(16, 8, (1, 1))\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2_5 = nn.Conv2d(32, 16, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv2_3 = nn.Conv2d(32, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.bn3 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(16, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ4 = nn.PReLU()\n",
    "        self.conv5 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(torch.cat((self.conv1_1(x), self.conv1_3(x), \n",
    "                                   self.conv1_5(x), self.conv1_7(x)), 1))\n",
    "        x = self.activ2(torch.cat((self.conv2_3(x), self.conv2_5(x)), 1))\n",
    "        x = self.activ3(self.bn3(self.conv3(x)))\n",
    "        x = self.activ4(self.conv4(x))\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-Reverse net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseForwardNet(nn.Module):\n",
    "    def __init__(self, ForwardNet, forward_wt_path, ReverseNet):\n",
    "        super(ReverseForwardNet, self).__init__()\n",
    "        self.reverse_net = ReverseNet()\n",
    "        # freeze the weights of the forward net\n",
    "        self.forward_net = ForwardNet()\n",
    "        self.forward_net.load_state_dict(torch.load(forward_wt_path))\n",
    "        for param in self.forward_net.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reverse_net(x)\n",
    "        x = self.forward_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReverseForwardNet(\n",
      "  (reverse_net): ReverseNetE(\n",
      "    (conv0): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activ0): ReLU()\n",
      "    (conv1_7): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=circular)\n",
      "    (conv1_5): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=circular)\n",
      "    (conv1_3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (conv1_1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activ1): PReLU(num_parameters=1)\n",
      "    (conv2_5): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=circular)\n",
      "    (conv2_3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ2): PReLU(num_parameters=1)\n",
      "    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activ3): PReLU(num_parameters=1)\n",
      "    (conv4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ4): PReLU(num_parameters=1)\n",
      "    (conv5): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "  )\n",
      "  (forward_net): RelaxedForwardNet(\n",
      "    (conv0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activ0): ReLU()\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ1): PReLU(num_parameters=1)\n",
      "    (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ2): PReLU(num_parameters=1)\n",
      "    (conv3): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ3): PReLU(num_parameters=1)\n",
      "    (conv4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION = 'E'\n",
    "\n",
    "if MODEL_VERSION == 'A':\n",
    "    ReverseNet = ReverseNetA\n",
    "elif MODEL_VERSION == 'B':\n",
    "    ReverseNet = ReverseNetB\n",
    "elif MODEL_VERSION == 'C':\n",
    "    ReverseNet = ReverseNetC\n",
    "elif MODEL_VERSION == 'D':\n",
    "    ReverseNet = ReverseNetD\n",
    "elif MODEL_VERSION == 'E':\n",
    "    ReverseNet = ReverseNetE\n",
    "\n",
    "rf_net = ReverseForwardNet(RelaxedForwardNet, relaxed_forward_model_path, ReverseNet)\n",
    "print(rf_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rf = Variable(torch.tensor(r_stop_boards).view(N_reverse, 1, 25, 25).float(), requires_grad=True)\n",
    "# y_rf = Variable(torch.tensor(r_stop_boards).view(N_reverse, 1, 25, 25).float())\n",
    "# X_valid_rf = y_valid\n",
    "# y_valid_rf = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = Variable(torch.tensor(stop_boards).view(N, 1, 25, 25).float(), requires_grad=True)\n",
    "y_rf = Variable(torch.tensor(stop_boards).view(N, 1, 25, 25).float())\n",
    "X_valid_rf = y_valid\n",
    "y_valid_rf = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_model_path = \"../models/johnson/reverse_forward_E.pkl\"\n",
    "# rf_net.load_state_dict(torch.load(rf_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the reverse forward model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1, 127745] loss: 0.093394 | train MAE 0.233419 | best MAE: 0.130036: 100%|██████████| 500/500 [01:58<00:00,  4.22it/s]\n",
      "[2, 127745] loss: 0.062408 | train MAE 0.177319 | best MAE: 0.130036: 100%|██████████| 500/500 [01:59<00:00,  4.20it/s]\n",
      "[3, 127745] loss: 0.056237 | train MAE 0.197019 | best MAE: 0.130036: 100%|██████████| 500/500 [01:58<00:00,  4.21it/s]\n",
      "[4, 127745] loss: 0.107583 | train MAE 0.102487 | best MAE: 0.098680: 100%|██████████| 500/500 [01:59<00:00,  4.20it/s]\n",
      "[5, 127745] loss: 0.069220 | train MAE 0.110450 | best MAE: 0.098680: 100%|██████████| 500/500 [01:59<00:00,  4.19it/s]\n",
      "[6, 127745] loss: 0.067185 | train MAE 0.115300 | best MAE: 0.098680: 100%|██████████| 500/500 [01:58<00:00,  4.21it/s]\n",
      "[7, 127745] loss: 0.060679 | train MAE 0.114000 | best MAE: 0.098680: 100%|██████████| 500/500 [01:56<00:00,  4.27it/s]\n",
      "[8, 127745] loss: 0.054566 | train MAE 0.108706 | best MAE: 0.098680: 100%|██████████| 500/500 [01:56<00:00,  4.29it/s]\n",
      "[9, 127745] loss: 0.051965 | train MAE 0.111637 | best MAE: 0.098680: 100%|██████████| 500/500 [01:56<00:00,  4.28it/s]\n",
      "[10, 127745] loss: 0.055971 | train MAE 0.123344 | best MAE: 0.098680: 100%|██████████| 500/500 [01:56<00:00,  4.28it/s]\n",
      "[11, 127745] loss: 0.045762 | train MAE 0.112962 | best MAE: 0.098680: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
      "[12, 127745] loss: 0.043259 | train MAE 0.111119 | best MAE: 0.098680: 100%|██████████| 500/500 [01:56<00:00,  4.28it/s]\n",
      "[13, 127745] loss: 0.040943 | train MAE 0.112281 | best MAE: 0.098680: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
      "[14, 127745] loss: 0.554446 | train MAE 0.157394 | best MAE: 0.087628: 100%|██████████| 500/500 [01:57<00:00,  4.27it/s]\n",
      "[15, 127745] loss: 0.055401 | train MAE 0.133369 | best MAE: 0.087628: 100%|██████████| 500/500 [01:56<00:00,  4.28it/s]\n",
      "[16, 127745] loss: 0.050238 | train MAE 0.130787 | best MAE: 0.087628: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
      "[17, 127745] loss: 0.039302 | train MAE 0.111450 | best MAE: 0.087628: 100%|██████████| 500/500 [01:59<00:00,  4.18it/s]\n",
      "[18, 127745] loss: 0.042547 | train MAE 0.116406 | best MAE: 0.087628: 100%|██████████| 500/500 [02:01<00:00,  4.11it/s]\n",
      "[19, 127745] loss: 0.036121 | train MAE 0.111394 | best MAE: 0.087628: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
      "[20, 127745] loss: 0.075357 | train MAE 0.106550 | best MAE: 0.087628: 100%|██████████| 500/500 [01:58<00:00,  4.23it/s]\n",
      "[21, 127745] loss: 0.035485 | train MAE 0.116975 | best MAE: 0.087628: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
      "[22, 127745] loss: 0.037977 | train MAE 0.110044 | best MAE: 0.087628: 100%|██████████| 500/500 [01:57<00:00,  4.24it/s]\n",
      "[23, 127745] loss: 0.034522 | train MAE 0.115644 | best MAE: 0.087628: 100%|██████████| 500/500 [01:58<00:00,  4.24it/s]\n",
      "[24, 127745] loss: 0.044751 | train MAE 0.116475 | best MAE: 0.080299: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
      "[25, 127745] loss: 0.038619 | train MAE 0.119475 | best MAE: 0.080299: 100%|██████████| 500/500 [01:57<00:00,  4.24it/s]\n",
      "[26, 127745] loss: 0.030935 | train MAE 0.109844 | best MAE: 0.080299: 100%|██████████| 500/500 [01:58<00:00,  4.22it/s]\n",
      "[27, 127745] loss: 0.028767 | train MAE 0.110537 | best MAE: 0.080299: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
      "[28, 127745] loss: 0.031951 | train MAE 0.115881 | best MAE: 0.080299: 100%|██████████| 500/500 [01:59<00:00,  4.18it/s]\n",
      "[29, 127745] loss: 0.029096 | train MAE 0.109225 | best MAE: 0.080299: 100%|██████████| 500/500 [02:00<00:00,  4.14it/s]\n",
      "[30, 127745] loss: 0.042081 | train MAE 0.110681 | best MAE: 0.080299: 100%|██████████| 500/500 [02:00<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation MAE: 0.0802989974617958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(rf_net, X_rf, y_rf, X_valid_rf, y_valid_rf, optim.Adam, criterion, rf_model_path, batch_size=256, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 10.91 GiB total capacity; 8.52 GiB already allocated; 328.69 MiB free; 8.59 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-25ade0c98610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Test data MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_forward_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stop_boards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stop_boards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The test data MAE is {:.6f}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-41c2dea13d25>\u001b[0m in \u001b[0;36mget_forward_mae\u001b[0;34m(model, weight_path, input_boards, output_boards, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reverse_net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpredicted_start_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_boards_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mpredicted_output_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactual_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_start_board\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-db24be8846ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         x = self.activ1(torch.cat((self.conv1_1(x), self.conv1_3(x), \n\u001b[1;32m     25\u001b[0m                                    self.conv1_5(x), self.conv1_7(x)), 1))\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/cs229/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 10.91 GiB total capacity; 8.52 GiB already allocated; 328.69 MiB free; 8.59 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Training data MAE\n",
    "# train_mae = get_forward_mae(rf_net, rf_model_path, stop_boards, stop_boards, N)\n",
    "# print(\"The training data MAE is {:.6f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "test_mae = get_forward_mae(rf_net, rf_model_path, test_stop_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.6f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
