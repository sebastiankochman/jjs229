{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'..')\n",
    "import bitmap\n",
    "import itertools\n",
    "from forward_prediction import forward_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load training data\n",
    "N = 128000\n",
    "\n",
    "if regenerate_data:\n",
    "    train_data_gen = bitmap.generate_train_set(N, 41, min_delta=1, max_delta=1)\n",
    "    deltas, start_boards, stop_boards = map(np.array, zip(*list(train_data_gen)))\n",
    "    # Save training data\n",
    "    np.save('../../data/training_start_boards', start_boards)\n",
    "    np.save('../../data/training_stop_boards', stop_boards)\n",
    "else:\n",
    "    start_boards = np.load('../../data/training_start_boards.npy')\n",
    "    stop_boards = np.load('../../data/training_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load validation data\n",
    "N_valid = 12800\n",
    "\n",
    "if regenerate_data:\n",
    "    valid_data_gen = bitmap.generate_train_set(N_valid, 1024, min_delta=1, max_delta=1)\n",
    "    deltas, valid_start_boards, valid_stop_boards = map(np.array, zip(*list(valid_data_gen)))\n",
    "    # Save validation data\n",
    "    np.save('../../data/valid_start_boards', valid_start_boards)\n",
    "    np.save('../../data/valid_stop_boards', valid_stop_boards)\n",
    "else:\n",
    "    valid_start_boards = np.load('../../data/valid_start_boards.npy')\n",
    "    valid_stop_boards = np.load('../../data/valid_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = Variable(torch.tensor(valid_start_boards).view(N_valid, 1, 25, 25).float())\n",
    "y_valid = Variable(torch.tensor(valid_stop_boards).view(N_valid, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load test data\n",
    "N_test = 25600\n",
    "\n",
    "if regenerate_data:\n",
    "    test_data_gen = bitmap.generate_train_set(N_test, 42, min_delta=1, max_delta=1)\n",
    "    deltas, test_start_boards, test_stop_boards = map(np.array, zip(*list(test_data_gen)))\n",
    "    # Save test data\n",
    "    np.save('../../data/test_start_boards', test_start_boards)\n",
    "    np.save('../../data/test_stop_boards', test_stop_boards)\n",
    "else:\n",
    "    test_start_boards = np.load('../../data/test_start_boards.npy')\n",
    "    test_stop_boards = np.load('../../data/test_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, X_valid, y_valid, \n",
    "          optim, criterion, output_path, num_epochs=50, batch_size=128):\n",
    "    # Release CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = optim(model.parameters())\n",
    "    \n",
    "    # Setup Tensorboard (https://pytorch.org/docs/stable/tensorboard.html)\n",
    "    writer = SummaryWriter()\n",
    "    writer.add_graph(model.cpu(), X)\n",
    "    model.cuda()\n",
    "\n",
    "    # Best validation MAE\n",
    "    best_valid_mae = 1\n",
    "    \n",
    "    # Train\n",
    "    n_iter = 0\n",
    "    for epoch in range(num_epochs): \n",
    "        permutation = torch.randperm(X.size()[0])\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(range(0, X.size()[0], batch_size))\n",
    "        for i in pbar:\n",
    "            n_iter += 1\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch = X[indices].cuda()\n",
    "            target = y[indices].cuda()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description(\"[{:d}, {:5d}] loss: {:.8f}\".format(epoch + 1, i + 1, loss.item()))    \n",
    "            \n",
    "            # Calculate MAE\n",
    "            output_boards = (outputs > 0.5).int()\n",
    "            mae = torch.sum(output_boards != target) / (batch_size * 25 * 25)\n",
    "            \n",
    "            # Write data to Tensorboard\n",
    "            writer.add_scalar('Loss/train', loss.item(), n_iter)\n",
    "            writer.add_scalar('MAE/train', mae.item(), n_iter)\n",
    "            \n",
    "            # Write boards and validation results to Tensorboard every 50 batches\n",
    "            if n_iter % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    valid_loss = 0\n",
    "                    valid_mae = 0\n",
    "                    m = 0\n",
    "                    for j in range(0, X_valid.size()[0], batch_size):\n",
    "                        m += 1\n",
    "                        valid_batch = X_valid[j:j+batch_size].cuda()\n",
    "                        valid_target = y_valid[j:j+batch_size].cuda()\n",
    "                        valid_outputs = model(valid_batch)\n",
    "                        valid_loss += criterion(valid_outputs, valid_target)\n",
    "                        valid_boards = (valid_outputs > 0.5).int()\n",
    "                        valid_mae += torch.sum(valid_boards != valid_target).float()\n",
    "                    valid_loss /= m\n",
    "                    valid_mae /= (X_valid.size()[0] * 25 * 25)\n",
    "                    writer.add_image('predicted stop board', valid_boards[-1], n_iter)\n",
    "                    writer.add_image('actual stop board', y_valid[-1], n_iter)\n",
    "                    if hasattr(model, \"reverse_net\"):\n",
    "                        pred_start_board = (model.reverse_net(X_valid[-1].view(1, 1, 25, 25).cuda()) > 0.5).int()\n",
    "                        writer.add_image('predicted start board', pred_start_board[-1], n_iter)\n",
    "                    writer.add_scalar('Loss/valid', valid_loss.item(), n_iter)\n",
    "                    writer.add_scalar('MAE/valid', valid_mae.item(), n_iter)\n",
    "                    \n",
    "                if valid_mae < best_valid_mae:\n",
    "                    best_valid_mae = valid_mae\n",
    "                    # Save model if we have the lastest best MAE\n",
    "                    torch.save(model.state_dict(), output_path)\n",
    "    writer.close()\n",
    "    print(\"The best validation MAE: {}\".format(best_valid_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForwardNet, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_net = ForwardNet()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.tensor(start_boards[:25600]).view(25600, 1, 25, 25).float(), requires_grad=True)\n",
    "y = Variable(torch.tensor(stop_boards[:25600]).view(25600, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_forward_model_path = \"../models/johnson/vanilla_forward.pkl\"\n",
    "forward_net.load_state_dict(torch.load(vanilla_forward_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the forward model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(forward_net, X, y, X_valid, y_valid, optim.Adam, criterion, vanilla_forward_model_path, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_mae(model, weight_path, start_boards, stop_boards, n):\n",
    "    # Release CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "    # Load model\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model.cuda()\n",
    "    # Convert boards to tensor\n",
    "    start_boards_tensor = torch.tensor(start_boards[:n]).view(n, 1, 25, 25).float().cuda()\n",
    "    stop_boards_tensor = torch.tensor(stop_boards[:n]).view(n, 1, 25, 25)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Make prediction\n",
    "        predicted_stop_board = (model(start_boards_tensor) > 0.5).int().cpu()\n",
    "        error = torch.sum(predicted_stop_board != stop_boards_tensor)\n",
    "        # print(predicted_stop_board)\n",
    "        # print(stop_boards_tensor)\n",
    "        return error / (n * 25 * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data MAE\n",
    "train_mae = get_forward_mae(forward_net, vanilla_forward_model_path, \n",
    "                            start_boards, stop_boards, 25600)\n",
    "print(\"The training data MAE is {:.8f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "test_mae = get_forward_mae(forward_net, vanilla_forward_model_path,\n",
    "                           test_start_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.8f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax starting boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify starting boards \n",
    "def relax_boards(boards):\n",
    "    np.random.seed(41)\n",
    "    return np.abs(np.random.rand(*boards.shape) / 2 - boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_start_boards = relax_boards(start_boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelaxedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelaxedForwardNet, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 8, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_forward_net = RelaxedForwardNet()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_relaxed = Variable(torch.tensor(relaxed_start_boards).view(N, 1, 25, 25).float(), requires_grad=True)\n",
    "y = Variable(torch.tensor(stop_boards).view(N, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_valid_start_boards = relax_boards(valid_start_boards)\n",
    "X_valid_relaxed = Variable(torch.tensor(relaxed_valid_start_boards).view(N_valid, 1, 25, 25).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relaxed_forward_model_path = \"../models/johnson/relaxed_forward.pkl\"\n",
    "# relaxed_forward_net.load_state_dict(torch.load(relaxed_forward_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the _relaxed_ forward model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1, 127937] loss: 0.00508801: 100%|██████████| 2000/2000 [03:44<00:00,  8.89it/s]\n",
      "[2, 127937] loss: 0.00510006: 100%|██████████| 2000/2000 [03:46<00:00,  8.84it/s]\n",
      "[3, 127937] loss: 16.40999985: 100%|██████████| 2000/2000 [03:45<00:00,  8.86it/s]\n",
      "[4, 127937] loss: 17.00000000: 100%|██████████| 2000/2000 [03:42<00:00,  8.98it/s]\n",
      "[5, 127937] loss: 15.84999943: 100%|██████████| 2000/2000 [03:41<00:00,  9.05it/s]\n",
      "[6, 127937] loss: 16.75749969: 100%|██████████| 2000/2000 [03:40<00:00,  9.05it/s]\n",
      "[7, 127937] loss: 16.39500046: 100%|██████████| 2000/2000 [03:40<00:00,  9.07it/s]\n",
      "[8, 127937] loss: 16.58250046: 100%|██████████| 2000/2000 [03:40<00:00,  9.06it/s]\n",
      "[9, 127937] loss: 14.63249969: 100%|██████████| 2000/2000 [03:40<00:00,  9.08it/s]\n",
      "[10, 127937] loss: 14.18249989: 100%|██████████| 2000/2000 [03:40<00:00,  9.06it/s]\n",
      "[11, 127937] loss: 16.26000023: 100%|██████████| 2000/2000 [03:40<00:00,  9.06it/s]\n",
      "[12, 127937] loss: 14.37749958: 100%|██████████| 2000/2000 [03:40<00:00,  9.07it/s]\n",
      "[13, 127937] loss: 14.66499996: 100%|██████████| 2000/2000 [03:40<00:00,  9.05it/s]\n",
      "[14, 127937] loss: 15.36499977: 100%|██████████| 2000/2000 [03:40<00:00,  9.07it/s]\n",
      "[15, 127937] loss: 13.07999992: 100%|██████████| 2000/2000 [03:40<00:00,  9.07it/s]\n",
      "[16, 127937] loss: 15.52749920: 100%|██████████| 2000/2000 [03:40<00:00,  9.06it/s]\n",
      "[17, 127937] loss: 14.43999958: 100%|██████████| 2000/2000 [03:40<00:00,  9.07it/s]\n",
      "[18, 127937] loss: 14.52749920: 100%|██████████| 2000/2000 [03:40<00:00,  9.05it/s]\n",
      "[19, 127937] loss: 15.47249985: 100%|██████████| 2000/2000 [03:41<00:00,  9.05it/s]\n",
      "[20, 127937] loss: 14.64999962: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[21, 127937] loss: 14.08999920: 100%|██████████| 2000/2000 [03:41<00:00,  9.03it/s]\n",
      "[22, 127937] loss: 17.87500000: 100%|██████████| 2000/2000 [03:41<00:00,  9.01it/s]\n",
      "[23, 127937] loss: 15.01749992: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[24, 127937] loss: 14.39249992: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[25, 127937] loss: 16.97999954: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[26, 127937] loss: 16.55249977: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[27, 127937] loss: 12.62249947: 100%|██████████| 2000/2000 [03:41<00:00,  9.01it/s]\n",
      "[28, 127937] loss: 16.18750000: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[29, 127937] loss: 15.09749985: 100%|██████████| 2000/2000 [03:41<00:00,  9.02it/s]\n",
      "[30, 127937] loss: 13.54500008: 100%|██████████| 2000/2000 [03:41<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation MAE: 0.0014865000266581774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(relaxed_forward_net, X_relaxed, y, X_valid_relaxed, y_valid, optim.Adam, criterion, relaxed_forward_model_path, batch_size=64, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data MAE is 0.001455.\n",
      "The test data MAE is 0.001464.\n"
     ]
    }
   ],
   "source": [
    "# Training data MAE\n",
    "train_mae = get_forward_mae(relaxed_forward_net, relaxed_forward_model_path, relaxed_start_boards, stop_boards, N // 2)\n",
    "print(\"The training data MAE is {:.6f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "relaxed_test_start_boards = relax_boards(test_start_boards)\n",
    "test_mae = get_forward_mae(relaxed_forward_net, relaxed_forward_model_path, relaxed_test_start_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.6f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New training data just for the reverse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load training data\n",
    "N_reverse = 51200\n",
    "\n",
    "if regenerate_data:\n",
    "    train_data_gen = bitmap.generate_train_set(N_reverse, 2, min_delta=1, max_delta=1)\n",
    "    deltas, r_start_boards, r_stop_boards = map(np.array, zip(*list(train_data_gen)))\n",
    "    # Save training data\n",
    "    np.save('../../data/reverse_start_boards', r_start_boards)\n",
    "    np.save('../../data/reverse_stop_boards', r_stop_boards)\n",
    "else:\n",
    "    r_start_boards = np.load('../../data/reverse_start_boards.npy')\n",
    "    r_stop_boards = np.load('../../data/reverse_stop_boards.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetA, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 4, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1_7 = nn.Conv2d(4, 4, (7, 7), padding=(3, 3), padding_mode='circular')\n",
    "        self.conv1_5 = nn.Conv2d(4, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv1_3 = nn.Conv2d(4, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.conv1_1 = nn.Conv2d(4, 4, (1, 1))\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2_5 = nn.Conv2d(16, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv2_3 = nn.Conv2d(16, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(torch.cat((self.conv1_1(x), self.conv1_3(x), \n",
    "                                   self.conv1_5(x), self.conv1_7(x)), 1))\n",
    "        x = self.activ2(torch.cat((self.conv2_3(x), self.conv2_5(x)), 1))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetB, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 4, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1_5 = nn.Conv2d(4, 8, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv1_3 = nn.Conv2d(4, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2_5 = nn.Conv2d(16, 4, (5, 5), padding=(2, 2), padding_mode='circular')\n",
    "        self.conv2_3 = nn.Conv2d(16, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(torch.cat((self.conv1_3(x), self.conv1_5(x)), 1))\n",
    "        x = self.activ2(torch.cat((self.conv2_3(x), self.conv2_5(x)), 1))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse model version C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseNetC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReverseNetC, self).__init__()\n",
    "        # in channels, out channels, kernel size\n",
    "        self.conv0 = nn.Conv2d(1, 8, (1, 1))\n",
    "        self.activ0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(8, 4, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "        self.activ3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(4, 1, (3, 3), padding=(1, 1), padding_mode='circular')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activ0(self.conv0(x))\n",
    "        x = self.activ1(self.conv1(x))\n",
    "        x = self.activ2(self.conv2(x))\n",
    "        x = self.activ3(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-Reverse net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseForwardNet(nn.Module):\n",
    "    def __init__(self, ForwardNet, forward_wt_path, ReverseNet):\n",
    "        super(ReverseForwardNet, self).__init__()\n",
    "        self.reverse_net = ReverseNet()\n",
    "        # freeze the weights of the forward net\n",
    "        self.forward_net = ForwardNet()\n",
    "        self.forward_net.load_state_dict(torch.load(forward_wt_path))\n",
    "        for param in self.forward_net.parameters():\n",
    "            param.require_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reverse_net(x)\n",
    "        x = self.forward_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReverseForwardNet(\n",
      "  (reverse_net): ReverseNetC(\n",
      "    (conv0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activ0): ReLU()\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ1): PReLU(num_parameters=1)\n",
      "    (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ2): PReLU(num_parameters=1)\n",
      "    (conv3): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ3): PReLU(num_parameters=1)\n",
      "    (conv4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "  )\n",
      "  (forward_net): RelaxedForwardNet(\n",
      "    (conv0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (activ0): ReLU()\n",
      "    (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ1): PReLU(num_parameters=1)\n",
      "    (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ2): PReLU(num_parameters=1)\n",
      "    (conv3): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "    (activ3): PReLU(num_parameters=1)\n",
      "    (conv4): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION = 'C'\n",
    "\n",
    "if MODEL_VERSION == 'A':\n",
    "    ReverseNet = ReverseNetA\n",
    "elif MODEL_VERSION == 'B':\n",
    "    ReverseNet = ReverseNetB\n",
    "elif MODEL_VERSION == 'C':\n",
    "    ReverseNet = ReverseNetC\n",
    "\n",
    "rf_net = ReverseForwardNet(RelaxedForwardNet, relaxed_forward_model_path, ReverseNet)\n",
    "print(rf_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = Variable(torch.tensor(r_stop_boards).view(N_reverse, 1, 25, 25).float(), requires_grad=True)\n",
    "y_rf = Variable(torch.tensor(r_stop_boards).view(N_reverse, 1, 25, 25).float())\n",
    "X_valid_rf = y_valid\n",
    "y_valid_rf = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_model_path = \"../models/johnson/reverse_forward.pkl\"\n",
    "# rf_net.load_state_dict(torch.load(rf_model_path));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment below to retrain the reverse model with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1, 51137] loss: 0.00000394: 100%|██████████| 800/800 [00:52<00:00, 15.15it/s]\n",
      "[2, 51137] loss: 0.00000935: 100%|██████████| 800/800 [00:51<00:00, 15.54it/s]\n",
      "[3, 51137] loss: 0.00000165: 100%|██████████| 800/800 [00:51<00:00, 15.56it/s]\n",
      "[4, 51137] loss: 0.00000525: 100%|██████████| 800/800 [00:51<00:00, 15.59it/s]\n",
      "[5, 51137] loss: 0.00000206: 100%|██████████| 800/800 [00:51<00:00, 15.56it/s]\n",
      "[6, 51137] loss: 0.00000150: 100%|██████████| 800/800 [00:51<00:00, 15.55it/s]\n",
      "[7, 51137] loss: 0.00000169: 100%|██████████| 800/800 [00:51<00:00, 15.51it/s]\n",
      "[8, 51137] loss: 0.00000107: 100%|██████████| 800/800 [00:51<00:00, 15.57it/s]\n",
      "[9, 51137] loss: 0.00000052: 100%|██████████| 800/800 [00:51<00:00, 15.47it/s]\n",
      "[10, 51137] loss: 0.00000158: 100%|██████████| 800/800 [00:51<00:00, 15.50it/s]\n",
      "[11, 51137] loss: 0.00000014: 100%|██████████| 800/800 [00:51<00:00, 15.53it/s]\n",
      "[12, 51137] loss: 0.00000022: 100%|██████████| 800/800 [00:51<00:00, 15.54it/s]\n",
      "[13, 51137] loss: 0.00000016: 100%|██████████| 800/800 [00:51<00:00, 15.50it/s]\n",
      "[14, 51137] loss: 0.00000020: 100%|██████████| 800/800 [00:51<00:00, 15.57it/s]\n",
      "[15, 51137] loss: 0.00000007: 100%|██████████| 800/800 [00:51<00:00, 15.56it/s]\n",
      "[16, 51137] loss: 16.59499931: 100%|██████████| 800/800 [00:51<00:00, 15.52it/s]\n",
      "[17, 51137] loss: 14.73749924: 100%|██████████| 800/800 [00:51<00:00, 15.51it/s]\n",
      "[18, 51137] loss: 15.59999943: 100%|██████████| 800/800 [00:51<00:00, 15.49it/s]\n",
      "[19, 51137] loss: 15.37500000: 100%|██████████| 800/800 [00:51<00:00, 15.48it/s]\n",
      "[20, 51137] loss: 15.61749935: 100%|██████████| 800/800 [00:51<00:00, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation MAE: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(rf_net, X_rf, y_rf, X_valid_rf, y_valid_rf, optim.Adam, criterion, rf_model_path, batch_size=64, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data MAE is 0.000000.\n",
      "The test data MAE is 0.000000.\n"
     ]
    }
   ],
   "source": [
    "# Training data MAE\n",
    "train_mae = get_forward_mae(rf_net, rf_model_path, r_stop_boards, r_stop_boards, N_reverse)\n",
    "print(\"The training data MAE is {:.6f}.\".format(train_mae))\n",
    "\n",
    "# Test data MAE\n",
    "test_mae = get_forward_mae(rf_net, rf_model_path, test_stop_boards, test_stop_boards, N_test)\n",
    "print(\"The test data MAE is {:.6f}.\".format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up the reverse net first before join training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reverse = X_rf\n",
    "y_reverse = Variable(torch.tensor(r_start_boards).view(N_reverse, 1, 25, 25).float())\n",
    "X_valid_reverse = X_valid_rf\n",
    "y_valid_reverse = X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_model_path = \"../models/johnson/reverse_forward.pkl\"\n",
    "# reverse_net.load_state_dict(torch.load(reverse_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(reverse_net, X_reverse, y_reverse, X_valid_reverse, y_valid_reverse, optim.Adam, criterion, reverse_forward_model_path, batch_size=64, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: CUDA memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
